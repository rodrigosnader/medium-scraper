{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from dalab import read_pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from time import time\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, SimpleRNN, GRU, LSTM\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>18872</th>\n",
       "      <td>forsale</td>\n",
       "      <td>Newsgroups: misc.forsale\\nPath: cantaloupe.srv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>hockey</td>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15811</th>\n",
       "      <td>guns</td>\n",
       "      <td>Newsgroups: talk.politics.guns\\nPath: cantalou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7404</th>\n",
       "      <td>crypt</td>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14644</th>\n",
       "      <td>electronics</td>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
=======
       "      <th>8373</th>\n",
       "      <td>artificial_intelligence</td>\n",
       "      <td>it has become a sort of tradition for me to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>transfer_learning</td>\n",
       "      <td>i’m building style transfer applications for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>computer_vision</td>\n",
       "      <td>init27 is an initiative by deep learning and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>data_science</td>\n",
       "      <td>data science for social good is now four year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>data_mining</td>\n",
       "      <td>data mining is the computational process of d...</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "             label                                               text\n",
       "18872      forsale  Newsgroups: misc.forsale\\nPath: cantaloupe.srv...\n",
       "6666        hockey  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...\n",
       "15811         guns  Newsgroups: talk.politics.guns\\nPath: cantalou...\n",
       "7404         crypt  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...\n",
       "14644  electronics  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club..."
=======
       "                         class  \\\n",
       "8373   artificial_intelligence   \n",
       "7822         transfer_learning   \n",
       "2250           computer_vision   \n",
       "10002             data_science   \n",
       "5222               data_mining   \n",
       "\n",
       "                                                   story  \n",
       "8373    it has become a sort of tradition for me to t...  \n",
       "7822    i’m building style transfer applications for ...  \n",
       "2250    init27 is an initiative by deep learning and ...  \n",
       "10002   data science for social good is now four year...  \n",
       "5222    data mining is the computational process of d...  "
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
=======
    "# df = pd.read_pickle('data/medium_stories/dataframes/en_lower_stories.pickle').reset_index(drop=True)\n",
    "# df = df.sample(frac=1)\n",
    "# df = df.drop_duplicates(subset='story')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12268</th>\n",
       "      <td>graphics</td>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19175</th>\n",
       "      <td>misc</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.magick:992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12385</th>\n",
       "      <td>graphics</td>\n",
       "      <td>Newsgroups: comp.graphics\\nPath: cantaloupe.sr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18956</th>\n",
       "      <td>misc</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.magick:100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12519</th>\n",
       "      <td>graphics</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.binaries.p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                               text\n",
       "12268  graphics  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...\n",
       "19175      misc  Xref: cantaloupe.srv.cs.cmu.edu alt.magick:992...\n",
       "12385  graphics  Newsgroups: comp.graphics\\nPath: cantaloupe.sr...\n",
       "18956      misc  Xref: cantaloupe.srv.cs.cmu.edu alt.magick:100...\n",
       "12519  graphics  Xref: cantaloupe.srv.cs.cmu.edu alt.binaries.p..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
    "df = read_pickle('data/20_newsgroup/dataframes/raw_news.pickle')\n",
    "df = df.sample(frac=1)\n",
    "df = df.drop_duplicates(subset='text')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('data/medium_stories/dataframes/en_lower_stories.pickle').reset_index(drop=True)\n",
    "# df = df.sample(frac=1)\n",
    "# df = df.drop_duplicates(subset='story')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
=======
   "execution_count": 22,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "forsale 990\n",
      "hockey 994\n",
      "guns 964\n",
      "crypt 998\n",
      "electronics 988\n",
      "hardware 1966\n",
      "x 992\n",
      "motorcycles 1000\n",
      "christian 997\n",
      "atheism 890\n",
      "autos 990\n",
      "baseball 993\n",
      "misc 2681\n",
      "mideast 980\n",
      "med 992\n",
      "graphics 985\n",
      "space 993\n"
=======
      "graphics 980\n",
      "misc 2704\n",
      "crypt 998\n",
      "hardware 1968\n",
      "forsale 990\n",
      "mideast 974\n",
      "x 992\n",
      "hockey 994\n",
      "motorcycles 1000\n",
      "autos 990\n",
      "med 997\n",
      "atheism 886\n",
      "guns 952\n",
      "electronics 987\n",
      "baseball 993\n",
      "christian 997\n",
      "space 991\n"
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "for topic in df['label'].unique():\n",
    "    print(topic, len(df[df['label'] == topic]))"
=======
    "for label in df.label.unique():\n",
    "    print(label, len(df[df.label == label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_multiple_labels(df, column, limit):\n",
    "    for topic in df[column].unique():\n",
    "        sample = df[df[column] == topic]\n",
    "        if len(sample) < limit:\n",
    "            df = df.drop(sample.index)\n",
    "\n",
    "    for topic in df[column].unique():\n",
    "        sample = df[df[column] == topic]\n",
    "        if len(sample) > limit:\n",
    "            df = df.drop(sample.index)\n",
    "            new_sample = sample.sample(limit)\n",
    "            df = df.append(new_sample)\n",
    "    return df"
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 25,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "metadata": {},
   "outputs": [],
   "source": [
    "df = balance_multiple_labels(df, 'label', 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAXLEN = 1000\n",
    "VOCAB_SIZE = 20000\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
=======
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 29,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = word_tokenize(' '.join(df.text.tolist()))\n",
    "word_counts = Counter(all_words).most_common(VOCAB_SIZE)\n",
    "words = [w[0] for w in word_counts]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 30,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [01:30, 220.35it/s]\n"
     ]
    }
   ],
   "source": [
    "embed_dic = {}\n",
    "for index, word in tqdm(enumerate(words)):\n",
    "    token = nlp(word)\n",
    "    embed_dic[token.text] = token.vector"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 31,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\u0002</th>\n",
<<<<<<< HEAD
       "      <td>-0.917688</td>\n",
       "      <td>1.594070</td>\n",
=======
       "      <td>-0.917690</td>\n",
       "      <td>1.594071</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "      <td>6.749008</td>\n",
       "      <td>0.536356</td>\n",
       "      <td>-1.675298</td>\n",
       "      <td>3.894897</td>\n",
       "      <td>-3.105777</td>\n",
<<<<<<< HEAD
       "      <td>2.663857</td>\n",
       "      <td>1.218641</td>\n",
       "      <td>-1.035807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425276</td>\n",
       "      <td>1.230748</td>\n",
=======
       "      <td>2.663858</td>\n",
       "      <td>1.218638</td>\n",
       "      <td>-1.035808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425276</td>\n",
       "      <td>1.230747</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "      <td>0.118247</td>\n",
       "      <td>-0.219932</td>\n",
       "      <td>0.352065</td>\n",
       "      <td>-0.254422</td>\n",
       "      <td>-0.038656</td>\n",
       "      <td>-1.410054</td>\n",
<<<<<<< HEAD
       "      <td>0.657522</td>\n",
=======
       "      <td>0.657523</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "      <td>-0.292479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.671140</td>\n",
       "      <td>-0.475780</td>\n",
       "      <td>1.225881</td>\n",
       "      <td>-0.533356</td>\n",
       "      <td>1.413613</td>\n",
       "      <td>2.528171</td>\n",
       "      <td>-0.030113</td>\n",
       "      <td>0.486535</td>\n",
       "      <td>3.412096</td>\n",
       "      <td>1.299004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361494</td>\n",
       "      <td>0.078374</td>\n",
       "      <td>-0.094767</td>\n",
       "      <td>-0.087820</td>\n",
       "      <td>-0.176552</td>\n",
       "      <td>0.149058</td>\n",
       "      <td>0.224980</td>\n",
       "      <td>-0.329079</td>\n",
       "      <td>0.187947</td>\n",
       "      <td>-0.189483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>1.499199</td>\n",
       "      <td>-0.151667</td>\n",
       "      <td>2.150064</td>\n",
       "      <td>1.835209</td>\n",
       "      <td>1.904099</td>\n",
       "      <td>2.142190</td>\n",
       "      <td>-1.108657</td>\n",
       "      <td>-1.281632</td>\n",
       "      <td>2.732129</td>\n",
       "      <td>2.948514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079698</td>\n",
       "      <td>-0.464940</td>\n",
       "      <td>1.290173</td>\n",
       "      <td>0.061074</td>\n",
       "      <td>-0.257399</td>\n",
       "      <td>-0.752442</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>0.132082</td>\n",
       "      <td>-0.440150</td>\n",
       "      <td>-0.476224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>0.630779</td>\n",
       "      <td>1.138583</td>\n",
       "      <td>2.530837</td>\n",
       "      <td>0.166182</td>\n",
       "      <td>3.076834</td>\n",
       "      <td>0.542186</td>\n",
       "      <td>-0.858886</td>\n",
       "      <td>0.884038</td>\n",
       "      <td>2.754835</td>\n",
       "      <td>-0.390934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297402</td>\n",
       "      <td>-0.254304</td>\n",
       "      <td>1.426802</td>\n",
       "      <td>-0.010306</td>\n",
       "      <td>-0.657113</td>\n",
       "      <td>-0.627470</td>\n",
       "      <td>0.097198</td>\n",
       "      <td>-0.183204</td>\n",
       "      <td>-0.213610</td>\n",
       "      <td>-0.170229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>2.040905</td>\n",
       "      <td>0.173398</td>\n",
       "      <td>2.365522</td>\n",
       "      <td>-1.138491</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>2.351219</td>\n",
       "      <td>-2.068765</td>\n",
       "      <td>-0.857941</td>\n",
       "      <td>0.967327</td>\n",
       "      <td>2.126301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527834</td>\n",
       "      <td>-0.229152</td>\n",
       "      <td>-0.059828</td>\n",
       "      <td>0.299519</td>\n",
       "      <td>-0.925736</td>\n",
       "      <td>-0.175775</td>\n",
       "      <td>0.280793</td>\n",
       "      <td>0.260768</td>\n",
       "      <td>0.674299</td>\n",
       "      <td>0.673200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;</th>\n",
       "      <td>-0.362177</td>\n",
       "      <td>-1.536422</td>\n",
       "      <td>0.681591</td>\n",
       "      <td>-0.254282</td>\n",
       "      <td>-0.020796</td>\n",
       "      <td>2.549081</td>\n",
       "      <td>1.063519</td>\n",
       "      <td>1.306450</td>\n",
       "      <td>1.050380</td>\n",
       "      <td>2.485575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.431889</td>\n",
       "      <td>-0.154748</td>\n",
       "      <td>-0.647066</td>\n",
       "      <td>-0.048509</td>\n",
       "      <td>0.023910</td>\n",
       "      <td>-0.560397</td>\n",
       "      <td>0.427393</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.882393</td>\n",
       "      <td>-0.388471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>-1.620778</td>\n",
       "      <td>2.052795</td>\n",
       "      <td>0.476202</td>\n",
       "      <td>-0.315579</td>\n",
       "      <td>0.532584</td>\n",
       "      <td>-0.451268</td>\n",
       "      <td>-1.238636</td>\n",
       "      <td>0.606206</td>\n",
       "      <td>-0.797014</td>\n",
       "      <td>0.126661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054849</td>\n",
       "      <td>-0.057004</td>\n",
       "      <td>0.090347</td>\n",
       "      <td>-0.235630</td>\n",
       "      <td>-0.785747</td>\n",
       "      <td>-0.306805</td>\n",
       "      <td>0.576140</td>\n",
       "      <td>0.273453</td>\n",
       "      <td>0.878228</td>\n",
       "      <td>0.013317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>-1.888850</td>\n",
       "      <td>-0.329436</td>\n",
       "      <td>2.229829</td>\n",
       "      <td>-0.024573</td>\n",
       "      <td>0.612867</td>\n",
       "      <td>1.830824</td>\n",
       "      <td>-2.658098</td>\n",
       "      <td>1.066224</td>\n",
       "      <td>-0.894128</td>\n",
       "      <td>0.677598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093398</td>\n",
       "      <td>-0.030841</td>\n",
       "      <td>-0.173364</td>\n",
       "      <td>-0.138874</td>\n",
       "      <td>-0.683034</td>\n",
       "      <td>-0.094501</td>\n",
       "      <td>0.465635</td>\n",
       "      <td>0.371119</td>\n",
       "      <td>0.759352</td>\n",
<<<<<<< HEAD
       "      <td>0.149494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'*</th>\n",
       "      <td>1.111745</td>\n",
       "      <td>1.290676</td>\n",
       "      <td>-0.382141</td>\n",
       "      <td>0.069083</td>\n",
=======
       "      <td>0.149495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'*</th>\n",
       "      <td>1.111743</td>\n",
       "      <td>1.290677</td>\n",
       "      <td>-0.382141</td>\n",
       "      <td>0.069084</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "      <td>-0.239147</td>\n",
       "      <td>0.952505</td>\n",
       "      <td>-1.702639</td>\n",
       "      <td>1.894596</td>\n",
       "      <td>1.396065</td>\n",
       "      <td>0.785170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027173</td>\n",
       "      <td>0.091146</td>\n",
       "      <td>-0.310856</td>\n",
       "      <td>-0.363376</td>\n",
       "      <td>-0.392699</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>-0.072186</td>\n",
       "      <td>0.011815</td>\n",
       "      <td>0.666233</td>\n",
       "      <td>-0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'+</th>\n",
<<<<<<< HEAD
       "      <td>0.697193</td>\n",
       "      <td>0.727430</td>\n",
       "      <td>0.795636</td>\n",
       "      <td>0.136264</td>\n",
       "      <td>0.777219</td>\n",
       "      <td>0.521605</td>\n",
       "      <td>-0.411750</td>\n",
       "      <td>0.238003</td>\n",
       "      <td>-0.009105</td>\n",
=======
       "      <td>0.697192</td>\n",
       "      <td>0.727430</td>\n",
       "      <td>0.795637</td>\n",
       "      <td>0.136264</td>\n",
       "      <td>0.777219</td>\n",
       "      <td>0.521606</td>\n",
       "      <td>-0.411749</td>\n",
       "      <td>0.238003</td>\n",
       "      <td>-0.009106</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "      <td>0.776705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075038</td>\n",
       "      <td>0.048530</td>\n",
       "      <td>0.151208</td>\n",
       "      <td>-0.007558</td>\n",
       "      <td>-0.555188</td>\n",
       "      <td>-0.124780</td>\n",
       "      <td>0.504512</td>\n",
       "      <td>0.432797</td>\n",
       "      <td>1.108591</td>\n",
<<<<<<< HEAD
       "      <td>0.201013</td>\n",
=======
       "      <td>0.201012</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
<<<<<<< HEAD
       "\u0002  -0.917688  1.594070  6.749008  0.536356 -1.675298  3.894897 -3.105777   \n",
       "!   0.671140 -0.475781  1.225882 -0.533356  1.413614  2.528172 -0.030113   \n",
       "#   1.499199 -0.151666  2.150062  1.835209  1.904099  2.142193 -1.108657   \n",
       "$   0.630779  1.138584  2.530838  0.166183  3.076835  0.542186 -0.858887   \n",
       "%   2.040906  0.173398  2.365521 -1.138491  0.034594  2.351219 -2.068765   \n",
       "&  -0.362176 -1.536422  0.681592 -0.254282 -0.020795  2.549080  1.063519   \n",
       "'  -1.620776  2.052795  0.476201 -0.315580  0.532586 -0.451270 -1.238636   \n",
       "'' -1.888850 -0.329437  2.229829 -0.024572  0.612867  1.830826 -2.658098   \n",
       "'*  1.111745  1.290676 -0.382141  0.069083 -0.239147  0.952505 -1.702639   \n",
       "'+  0.697193  0.727430  0.795636  0.136264  0.777219  0.521605 -0.411750   \n",
       "\n",
       "         7         8         9      ...          374       375       376  \\\n",
       "\u0002   2.663857  1.218641 -1.035807    ...     0.425276  1.230748  0.118247   \n",
       "!   0.486537  3.412096  1.299003    ...     0.361494  0.078374 -0.094767   \n",
       "#  -1.281631  2.732129  2.948512    ...     0.079698 -0.464941  1.290173   \n",
       "$   0.884039  2.754835 -0.390936    ...     0.297402 -0.254304  1.426802   \n",
       "%  -0.857941  0.967327  2.126300    ...    -0.527834 -0.229152 -0.059828   \n",
       "&   1.306450  1.050382  2.485573    ...    -0.431890 -0.154748 -0.647066   \n",
       "'   0.606207 -0.797014  0.126661    ...     0.054849 -0.057004  0.090347   \n",
       "''  1.066225 -0.894128  0.677597    ...    -0.093398 -0.030841 -0.173364   \n",
       "'*  1.894596  1.396065  0.785170    ...    -0.027173  0.091146 -0.310856   \n",
       "'+  0.238003 -0.009105  0.776705    ...     0.075038  0.048530  0.151208   \n",
       "\n",
       "         377       378       379       380       381       382       383  \n",
       "\u0002  -0.219932  0.352065 -0.254422 -0.038656 -1.410054  0.657522 -0.292479  \n",
       "!  -0.087820 -0.176552  0.149058  0.224980 -0.329079  0.187947 -0.189483  \n",
       "#   0.061074 -0.257399 -0.752442  0.019620  0.132082 -0.440150 -0.476223  \n",
       "$  -0.010306 -0.657113 -0.627469  0.097199 -0.183204 -0.213610 -0.170229  \n",
       "%   0.299519 -0.925737 -0.175775  0.280792  0.260768  0.674299  0.673200  \n",
       "&  -0.048509  0.023910 -0.560396  0.427393  0.642400  0.882393 -0.388471  \n",
       "'  -0.235629 -0.785747 -0.306805  0.576140  0.273453  0.878228  0.013317  \n",
       "'' -0.138874 -0.683034 -0.094501  0.465635  0.371119  0.759352  0.149494  \n",
       "'* -0.363376 -0.392699  0.008236 -0.072186  0.011815  0.666233 -0.253421  \n",
       "'+ -0.007558 -0.555188 -0.124780  0.504512  0.432797  1.108591  0.201013  \n",
=======
       "\u0002  -0.917690  1.594071  6.749008  0.536356 -1.675298  3.894897 -3.105777   \n",
       "!   0.671140 -0.475780  1.225881 -0.533356  1.413613  2.528171 -0.030113   \n",
       "#   1.499199 -0.151667  2.150064  1.835209  1.904099  2.142190 -1.108657   \n",
       "$   0.630779  1.138583  2.530837  0.166182  3.076834  0.542186 -0.858886   \n",
       "%   2.040905  0.173398  2.365522 -1.138491  0.034594  2.351219 -2.068765   \n",
       "&  -0.362177 -1.536422  0.681591 -0.254282 -0.020796  2.549081  1.063519   \n",
       "'  -1.620778  2.052795  0.476202 -0.315579  0.532584 -0.451268 -1.238636   \n",
       "'' -1.888850 -0.329436  2.229829 -0.024573  0.612867  1.830824 -2.658098   \n",
       "'*  1.111743  1.290677 -0.382141  0.069084 -0.239147  0.952505 -1.702639   \n",
       "'+  0.697192  0.727430  0.795637  0.136264  0.777219  0.521606 -0.411749   \n",
       "\n",
       "         7         8         9      ...          374       375       376  \\\n",
       "\u0002   2.663858  1.218638 -1.035808    ...     0.425276  1.230747  0.118247   \n",
       "!   0.486535  3.412096  1.299004    ...     0.361494  0.078374 -0.094767   \n",
       "#  -1.281632  2.732129  2.948514    ...     0.079698 -0.464940  1.290173   \n",
       "$   0.884038  2.754835 -0.390934    ...     0.297402 -0.254304  1.426802   \n",
       "%  -0.857941  0.967327  2.126301    ...    -0.527834 -0.229152 -0.059828   \n",
       "&   1.306450  1.050380  2.485575    ...    -0.431889 -0.154748 -0.647066   \n",
       "'   0.606206 -0.797014  0.126661    ...     0.054849 -0.057004  0.090347   \n",
       "''  1.066224 -0.894128  0.677598    ...    -0.093398 -0.030841 -0.173364   \n",
       "'*  1.894596  1.396065  0.785170    ...    -0.027173  0.091146 -0.310856   \n",
       "'+  0.238003 -0.009106  0.776705    ...     0.075038  0.048530  0.151208   \n",
       "\n",
       "         377       378       379       380       381       382       383  \n",
       "\u0002  -0.219932  0.352065 -0.254422 -0.038656 -1.410054  0.657523 -0.292479  \n",
       "!  -0.087820 -0.176552  0.149058  0.224980 -0.329079  0.187947 -0.189483  \n",
       "#   0.061074 -0.257399 -0.752442  0.019620  0.132082 -0.440150 -0.476224  \n",
       "$  -0.010306 -0.657113 -0.627470  0.097198 -0.183204 -0.213610 -0.170229  \n",
       "%   0.299519 -0.925736 -0.175775  0.280793  0.260768  0.674299  0.673200  \n",
       "&  -0.048509  0.023910 -0.560397  0.427393  0.642400  0.882393 -0.388471  \n",
       "'  -0.235630 -0.785747 -0.306805  0.576140  0.273453  0.878228  0.013317  \n",
       "'' -0.138874 -0.683034 -0.094501  0.465635  0.371119  0.759352  0.149495  \n",
       "'* -0.363376 -0.392699  0.008236 -0.072186  0.011815  0.666233 -0.253421  \n",
       "'+ -0.007558 -0.555188 -0.124780  0.504512  0.432797  1.108591  0.201012  \n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "\n",
       "[10 rows x 384 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 10,
=======
     "execution_count": 31,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_words = pd.DataFrame(embed_dic).T\n",
    "embed_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 32,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;PAD&gt;</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\u0002</th>\n",
<<<<<<< HEAD
       "      <td>-0.917688</td>\n",
       "      <td>1.594070</td>\n",
=======
       "      <td>-0.917690</td>\n",
       "      <td>1.594071</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "      <td>6.749008</td>\n",
       "      <td>0.536356</td>\n",
       "      <td>-1.675298</td>\n",
       "      <td>3.894897</td>\n",
       "      <td>-3.105777</td>\n",
<<<<<<< HEAD
       "      <td>2.663857</td>\n",
       "      <td>1.218641</td>\n",
       "      <td>-1.035807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425276</td>\n",
       "      <td>1.230748</td>\n",
=======
       "      <td>2.663858</td>\n",
       "      <td>1.218638</td>\n",
       "      <td>-1.035808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425276</td>\n",
       "      <td>1.230747</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "      <td>0.118247</td>\n",
       "      <td>-0.219932</td>\n",
       "      <td>0.352065</td>\n",
       "      <td>-0.254422</td>\n",
       "      <td>-0.038656</td>\n",
       "      <td>-1.410054</td>\n",
<<<<<<< HEAD
       "      <td>0.657522</td>\n",
=======
       "      <td>0.657523</td>\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "      <td>-0.292479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.671140</td>\n",
       "      <td>-0.475780</td>\n",
       "      <td>1.225881</td>\n",
       "      <td>-0.533356</td>\n",
       "      <td>1.413613</td>\n",
       "      <td>2.528171</td>\n",
       "      <td>-0.030113</td>\n",
       "      <td>0.486535</td>\n",
       "      <td>3.412096</td>\n",
       "      <td>1.299004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361494</td>\n",
       "      <td>0.078374</td>\n",
       "      <td>-0.094767</td>\n",
       "      <td>-0.087820</td>\n",
       "      <td>-0.176552</td>\n",
       "      <td>0.149058</td>\n",
       "      <td>0.224980</td>\n",
       "      <td>-0.329079</td>\n",
       "      <td>0.187947</td>\n",
       "      <td>-0.189483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>1.499199</td>\n",
       "      <td>-0.151667</td>\n",
       "      <td>2.150064</td>\n",
       "      <td>1.835209</td>\n",
       "      <td>1.904099</td>\n",
       "      <td>2.142190</td>\n",
       "      <td>-1.108657</td>\n",
       "      <td>-1.281632</td>\n",
       "      <td>2.732129</td>\n",
       "      <td>2.948514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079698</td>\n",
       "      <td>-0.464940</td>\n",
       "      <td>1.290173</td>\n",
       "      <td>0.061074</td>\n",
       "      <td>-0.257399</td>\n",
       "      <td>-0.752442</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>0.132082</td>\n",
       "      <td>-0.440150</td>\n",
       "      <td>-0.476224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>0.630779</td>\n",
       "      <td>1.138583</td>\n",
       "      <td>2.530837</td>\n",
       "      <td>0.166182</td>\n",
       "      <td>3.076834</td>\n",
       "      <td>0.542186</td>\n",
       "      <td>-0.858886</td>\n",
       "      <td>0.884038</td>\n",
       "      <td>2.754835</td>\n",
       "      <td>-0.390934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297402</td>\n",
       "      <td>-0.254304</td>\n",
       "      <td>1.426802</td>\n",
       "      <td>-0.010306</td>\n",
       "      <td>-0.657113</td>\n",
       "      <td>-0.627470</td>\n",
       "      <td>0.097198</td>\n",
       "      <td>-0.183204</td>\n",
       "      <td>-0.213610</td>\n",
       "      <td>-0.170229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "<PAD>  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
<<<<<<< HEAD
       "\u0002     -0.917688  1.594070  6.749008  0.536356 -1.675298  3.894897 -3.105777   \n",
       "!      0.671140 -0.475781  1.225882 -0.533356  1.413614  2.528172 -0.030113   \n",
       "#      1.499199 -0.151666  2.150062  1.835209  1.904099  2.142193 -1.108657   \n",
       "$      0.630779  1.138584  2.530838  0.166183  3.076835  0.542186 -0.858887   \n",
       "\n",
       "            7         8         9      ...          374       375       376  \\\n",
       "<PAD>  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "\u0002      2.663857  1.218641 -1.035807    ...     0.425276  1.230748  0.118247   \n",
       "!      0.486537  3.412096  1.299003    ...     0.361494  0.078374 -0.094767   \n",
       "#     -1.281631  2.732129  2.948512    ...     0.079698 -0.464941  1.290173   \n",
       "$      0.884039  2.754835 -0.390936    ...     0.297402 -0.254304  1.426802   \n",
       "\n",
       "            377       378       379       380       381       382       383  \n",
       "<PAD>  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\u0002     -0.219932  0.352065 -0.254422 -0.038656 -1.410054  0.657522 -0.292479  \n",
       "!     -0.087820 -0.176552  0.149058  0.224980 -0.329079  0.187947 -0.189483  \n",
       "#      0.061074 -0.257399 -0.752442  0.019620  0.132082 -0.440150 -0.476223  \n",
       "$     -0.010306 -0.657113 -0.627469  0.097199 -0.183204 -0.213610 -0.170229  \n",
=======
       "\u0002     -0.917690  1.594071  6.749008  0.536356 -1.675298  3.894897 -3.105777   \n",
       "!      0.671140 -0.475780  1.225881 -0.533356  1.413613  2.528171 -0.030113   \n",
       "#      1.499199 -0.151667  2.150064  1.835209  1.904099  2.142190 -1.108657   \n",
       "$      0.630779  1.138583  2.530837  0.166182  3.076834  0.542186 -0.858886   \n",
       "\n",
       "            7         8         9      ...          374       375       376  \\\n",
       "<PAD>  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "\u0002      2.663858  1.218638 -1.035808    ...     0.425276  1.230747  0.118247   \n",
       "!      0.486535  3.412096  1.299004    ...     0.361494  0.078374 -0.094767   \n",
       "#     -1.281632  2.732129  2.948514    ...     0.079698 -0.464940  1.290173   \n",
       "$      0.884038  2.754835 -0.390934    ...     0.297402 -0.254304  1.426802   \n",
       "\n",
       "            377       378       379       380       381       382       383  \n",
       "<PAD>  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\u0002     -0.219932  0.352065 -0.254422 -0.038656 -1.410054  0.657523 -0.292479  \n",
       "!     -0.087820 -0.176552  0.149058  0.224980 -0.329079  0.187947 -0.189483  \n",
       "#      0.061074 -0.257399 -0.752442  0.019620  0.132082 -0.440150 -0.476224  \n",
       "$     -0.010306 -0.657113 -0.627470  0.097198 -0.183204 -0.213610 -0.170229  \n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 11,
=======
     "execution_count": 32,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding = pd.DataFrame({'<PAD>': np.zeros(shape=[1,embed_words.shape[1]])[0]}).T\n",
    "embed_matrix = padding.append(embed_words)\n",
    "embed_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {},
=======
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "outputs": [],
   "source": [
    "word_index = {j:i+1 for i,j in enumerate(embed_matrix.index.tolist()[1:])}\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.word_index = word_index\n",
    "sequences = tokenizer.texts_to_sequences(df.text)\n",
    "data = pad_sequences(sequences, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
=======
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "outputs": [],
   "source": [
    "random_matrix = np.random.randn(embed_matrix.shape[0], embed_matrix.shape[1])\n",
    "random_matrix[0] = np.zeros([1, embed_matrix.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 35,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
<<<<<<< HEAD
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
=======
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = pd.get_dummies(df['label'])\n",
    "target_labels = onehot.columns\n",
    "target = onehot.as_matrix()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 36,
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/data.max()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15514 samples, validate on 3879 samples\n",
      "Epoch 1/2\n",
      "15514/15514 [==============================] - 552s - loss: 2.1881 - acc: 0.2799 - val_loss: 1.1939 - val_acc: 0.6190\n",
      "Epoch 2/2\n",
      "15514/15514 [==============================] - 518s - loss: 0.6827 - acc: 0.7771 - val_loss: 0.2662 - val_acc: 0.9314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14a361f98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(embed_matrix), len(embed_matrix.columns), input_length=MAXLEN, weights=[embed_matrix],\n",
    "                           trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAXLEN,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
=======
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.58047877, 0.57627204,\n",
       "        0.57627204],\n",
       "       [0.        , 0.        , 0.        , ..., 0.05719151, 0.48627804,\n",
       "        0.58047877],\n",
       "       [0.        , 0.        , 0.        , ..., 0.98532652, 0.58032853,\n",
       "        0.51527444],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.42698317, 0.78460537,\n",
       "        0.97105369],\n",
       "       [0.        , 0.        , 0.        , ..., 0.60957532, 0.61137821,\n",
       "        0.76872997],\n",
       "       [0.        , 0.        , 0.        , ..., 0.94265825, 0.78946314,\n",
       "        0.73207131]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = int(0.8 * len(data))\n",
    "\n",
    "x_train = data[:TRAIN_SIZE]\n",
    "x_test = data[TRAIN_SIZE:]\n",
    "\n",
    "y_train = target[:TRAIN_SIZE]\n",
    "y_test = target[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11520 samples, validate on 2880 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.5865 - acc: 0.0752 - val_loss: 6.4346 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 10s - loss: 2.5688 - acc: 0.0752 - val_loss: 8.0693 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 10s - loss: 2.5655 - acc: 0.0765 - val_loss: 7.5530 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 10s - loss: 2.5652 - acc: 0.0752 - val_loss: 6.8016 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 10s - loss: 2.5641 - acc: 0.0819 - val_loss: 7.2698 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      " - 10s - loss: 2.5641 - acc: 0.0730 - val_loss: 7.5392 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      " - 10s - loss: 2.5637 - acc: 0.0773 - val_loss: 7.9959 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      " - 10s - loss: 2.5635 - acc: 0.0747 - val_loss: 8.0127 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      " - 10s - loss: 2.5629 - acc: 0.0751 - val_loss: 7.9182 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      " - 10s - loss: 2.5626 - acc: 0.0834 - val_loss: 8.0354 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      " - 10s - loss: 2.5625 - acc: 0.0772 - val_loss: 8.2547 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      " - 10s - loss: 2.5622 - acc: 0.0737 - val_loss: 8.2440 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      " - 10s - loss: 2.5623 - acc: 0.0757 - val_loss: 8.8726 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      " - 10s - loss: 2.5618 - acc: 0.0793 - val_loss: 9.2227 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      " - 10s - loss: 2.5624 - acc: 0.0733 - val_loss: 9.1702 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      " - 10s - loss: 2.5619 - acc: 0.0759 - val_loss: 8.9990 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      " - 10s - loss: 2.5618 - acc: 0.0769 - val_loss: 9.3051 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      " - 10s - loss: 2.5620 - acc: 0.0759 - val_loss: 9.6033 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      " - 10s - loss: 2.5619 - acc: 0.0772 - val_loss: 9.0790 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      " - 10s - loss: 2.5615 - acc: 0.0819 - val_loss: 9.5364 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      " - 10s - loss: 2.5616 - acc: 0.0751 - val_loss: 9.2177 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      " - 10s - loss: 2.5615 - acc: 0.0740 - val_loss: 9.5981 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      " - 10s - loss: 2.5613 - acc: 0.0785 - val_loss: 9.8618 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      " - 10s - loss: 2.5616 - acc: 0.0770 - val_loss: 9.7845 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      " - 10s - loss: 2.5614 - acc: 0.0735 - val_loss: 9.6992 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      " - 10s - loss: 2.5614 - acc: 0.0766 - val_loss: 9.8440 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      " - 10s - loss: 2.5612 - acc: 0.0768 - val_loss: 10.0069 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      " - 10s - loss: 2.5613 - acc: 0.0790 - val_loss: 10.1457 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      " - 10s - loss: 2.5614 - acc: 0.0724 - val_loss: 10.1919 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-5c734f2e4614>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(embed_matrix), len(embed_matrix.columns), input_length=MAXLEN, weights=[random_matrix],\n",
    "                           trainable=True)\n",
    "\n",
    "sequence_input = Input(shape=(MAXLEN,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
<<<<<<< HEAD
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(target.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, output)\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-3, decay=1e-5)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "model.fit(data, target, validation_split=0.2, epochs=2, batch_size=128)"
=======
    "x = MaxPooling1D(35)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(target.shape[1], activation='softmax')(x)\n",
    "model = Model(sequence_input, output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(data, target, validation_split=0.2, epochs=100, batch_size=32, verbose=2)"
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "collapsed": true
   },
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
>>>>>>> d4343a4f8b06f2d38fa93a3cf7338c66aa9ab47d
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
