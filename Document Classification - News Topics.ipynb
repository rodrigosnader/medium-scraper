{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from dalab import read_pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from time import time\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, SimpleRNN, GRU, LSTM\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>18581</th>\n",
       "      <td>forsale</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu comp.sys.mac.w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12950</th>\n",
       "      <td>hardware</td>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>motorcycles</td>\n",
       "      <td>Newsgroups: rec.motorcycles\\nPath: cantaloupe....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11652</th>\n",
       "      <td>x</td>\n",
       "      <td>Newsgroups: comp.windows.x\\nPath: cantaloupe.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>hockey</td>\n",
       "      <td>Newsgroups: rec.sport.hockey\\nPath: cantaloupe...</td>\n",
=======
       "      <th>19394</th>\n",
       "      <td>misc</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu talk.religion....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>crypt</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu sci.crypt:1571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19374</th>\n",
       "      <td>misc</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14804</th>\n",
       "      <td>electronics</td>\n",
       "      <td>Newsgroups: sci.electronics\\nPath: cantaloupe....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11602</th>\n",
       "      <td>x</td>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                               text\n",
<<<<<<< HEAD
       "18581      forsale  Xref: cantaloupe.srv.cs.cmu.edu comp.sys.mac.w...\n",
       "12950     hardware  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...\n",
       "10545  motorcycles  Newsgroups: rec.motorcycles\\nPath: cantaloupe....\n",
       "11652            x  Newsgroups: comp.windows.x\\nPath: cantaloupe.s...\n",
       "6833        hockey  Newsgroups: rec.sport.hockey\\nPath: cantaloupe..."
=======
       "19394         misc  Xref: cantaloupe.srv.cs.cmu.edu talk.religion....\n",
       "7501         crypt  Xref: cantaloupe.srv.cs.cmu.edu sci.crypt:1571...\n",
       "19374         misc  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...\n",
       "14804  electronics  Newsgroups: sci.electronics\\nPath: cantaloupe....\n",
       "11602            x  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva..."
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_pickle('data/20_newsgroup/dataframes/raw_news.pickle')\n",
    "df = df.sample(frac=1)\n",
    "df = df.drop_duplicates(subset='text')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!hellgate.utah.edu!cc.usu.edu!slzw0\\nFrom: slzw0@cc.usu.edu\\nNewsgroups: comp.sys.ibm.pc.hardware\\nSubject: ***Wanted : 386DX-33 motherboard\\nMessage-ID: <1993Apr22.223127.66661@cc.usu.edu>\\nDate: 22 Apr 93 22:31:27 MDT\\nOrganization: Utah State University\\nLines: 10\\n\\n\\n  Are there anyone who wants to sell used 386dx-33 motherboard?\\nIf you have one please let me know the price and the specification\\n\\nI am also interested in buying Trident VGA card  (1Meg)\\n\\nPark\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAXLEN = 1000\n",
    "VOCAB_SIZE = 20000\n",
    "TRAIN_SIZE = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Language not supported: en_core_web_sm",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4fffa85c97b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, tokenizer, parser, tagger, entity, matcher, serializer, vectors, via)\u001b[0m\n\u001b[0;32m     13\u001b[0m def load(name, vocab=None, tokenizer=None, parser=None, tagger=None, entity=None,\n\u001b[0;32m     14\u001b[0m          matcher=None, serializer=None, vectors=None, via=None):\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mpackage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_package_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvia\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvia\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mvectors_package\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_package_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvia\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvia\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lang_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mget_package_by_name\u001b[1;34m(name, via)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mlang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lang_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         return sputnik.package(about.__title__, about.__version__,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mget_lang_class\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mlang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^a-zA-Z0-9_]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLANGUAGES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Language not supported: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mLANGUAGES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Language not supported: en_core_web_sm"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing here:\n",
    "# Lower, remove unwanted chars, decide if is going to keep punctuations, lemmas, so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = word_tokenize(' '.join(df.text.tolist()))\n",
    "word_counts = Counter(all_words).most_common(VOCAB_SIZE)\n",
    "words = [w[0] for w in word_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_dic = {}\n",
    "for index, word in enumerate(words):\n",
    "    if index % 500 == 0: print(index)\n",
    "    token = nlp(word)\n",
    "    embed_dic[token.text] = token.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_words = pd.DataFrame(embed_dic).T\n",
    "embed_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "padding = pd.DataFrame({'<PAD>': np.zeros(shape=[1,embed_words.shape[1]])[0]}).T\n",
    "embed_matrix = padding.append(embed_words)\n",
    "embed_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_matrix = np.random.randn(embed_matrix.shape[0], embed_matrix.shape[1])\n",
    "random_matrix[0] = np.zeros([1, embed_matrix.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = {j:i+1 for i,j in enumerate(embed_matrix.index.tolist()[1:])}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 12,
   "metadata": {},
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.word_index = word_index\n",
    "sequences = tokenizer.texts_to_sequences(df.text)\n",
    "data = pad_sequences(sequences, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.     ],\n",
       "       [0.5307 ],\n",
       "       [0.92545],\n",
       "       [0.8407 ],\n",
       "       [0.7324 ],\n",
       "       [0.92545],\n",
       "       [0.80025],\n",
       "       [0.6359 ],\n",
       "       [0.534  ],\n",
       "       [0.6833 ],\n",
       "       [0.7555 ],\n",
       "       [0.92545],\n",
       "       [0.8407 ],\n",
       "       [0.7324 ],\n",
       "       [0.92545],\n",
       "       [0.80025],\n",
       "       [0.6359 ],\n",
       "       [0.534  ],\n",
       "       [0.6833 ],\n",
       "       [0.7856 ],\n",
       "       [0.5307 ],\n",
       "       [0.5307 ],\n",
       "       [0.5014 ],\n",
       "       [0.65315],\n",
       "       [0.7499 ],\n",
       "       [0.9058 ],\n",
       "       [0.65335],\n",
       "       [0.5014 ],\n",
       "       [0.7571 ],\n",
       "       [0.5014 ],\n",
       "       [0.99465],\n",
       "       [0.99465],\n",
       "       [0.6357 ],\n",
       "       [0.5508 ],\n",
       "       [0.5307 ],\n",
       "       [0.47385],\n",
       "       [0.75145],\n",
       "       [0.47385],\n",
       "       [0.82535],\n",
       "       [0.47385],\n",
       "       [0.735  ],\n",
       "       [0.6178 ],\n",
       "       [0.735  ],\n",
       "       [0.803  ],\n",
       "       [0.47385],\n",
       "       [0.70105],\n",
       "       [0.91385],\n",
       "       [0.83045],\n",
       "       [0.75635],\n",
       "       [0.42575],\n",
       "       [0.68335],\n",
       "       [0.7276 ],\n",
       "       [0.65715],\n",
       "       [0.82535],\n",
       "       [0.47385],\n",
       "       [0.8748 ],\n",
       "       [0.735  ],\n",
       "       [0.82535],\n",
       "       [0.47385],\n",
       "       [0.70105],\n",
       "       [0.77475],\n",
       "       [0.8551 ],\n",
       "       [0.7302 ],\n",
       "       [0.50055],\n",
       "       [0.44505],\n",
       "       [0.47365],\n",
       "       [0.83635],\n",
       "       [0.03595],\n",
       "       [0.05805],\n",
       "       [0.9639 ],\n",
       "       [0.7433 ],\n",
       "       [0.95445],\n",
       "       [0.7433 ],\n",
       "       [0.53905],\n",
       "       [0.039  ],\n",
       "       [0.0327 ],\n",
       "       [0.02515],\n",
       "       [0.04685],\n",
       "       [0.02175],\n",
       "       [0.70605],\n",
       "       [0.0641 ],\n",
       "       [0.6629 ],\n",
       "       [0.4355 ],\n",
       "       [0.7433 ],\n",
       "       [0.7986 ],\n",
       "       [0.79065],\n",
       "       [0.9927 ],\n",
       "       [0.6629 ],\n",
       "       [0.4355 ],\n",
       "       [0.95445],\n",
       "       [0.6025 ],\n",
       "       [0.95445],\n",
       "       [0.6162 ],\n",
       "       [0.9927 ],\n",
       "       [0.42895],\n",
       "       [0.7687 ],\n",
       "       [0.98955],\n",
       "       [0.9838 ],\n",
       "       [0.47245],\n",
       "       [0.6119 ],\n",
       "       [0.76755],\n",
       "       [0.9918 ],\n",
       "       [0.64145],\n",
       "       [0.9883 ],\n",
       "       [0.98195],\n",
       "       [0.55415],\n",
       "       [0.9303 ],\n",
       "       [0.64815],\n",
       "       [0.5578 ],\n",
       "       [0.9412 ],\n",
       "       [0.43395],\n",
       "       [0.93425],\n",
       "       [0.88255],\n",
       "       [0.45275],\n",
       "       [0.64815],\n",
       "       [0.6563 ],\n",
       "       [0.45395],\n",
       "       [0.9337 ],\n",
       "       [0.59045],\n",
       "       [0.82495],\n",
       "       [0.97955],\n",
       "       [0.42035],\n",
       "       [0.9337 ],\n",
       "       [0.70605],\n",
       "       [0.76755],\n",
       "       [0.65825],\n",
       "       [0.99595],\n",
       "       [0.64145],\n",
       "       [0.89565],\n",
       "       [0.87415],\n",
       "       [0.6807 ],\n",
       "       [0.42575],\n",
       "       [0.47295],\n",
       "       [0.40265],\n",
       "       [0.92255],\n",
       "       [0.9365 ],\n",
       "       [0.6178 ],\n",
       "       [0.40265],\n",
       "       [0.6362 ],\n",
       "       [0.98495],\n",
       "       [0.80535],\n",
       "       [0.71125],\n",
       "       [0.76755],\n",
       "       [0.8041 ],\n",
       "       [0.9412 ],\n",
       "       [0.6287 ],\n",
       "       [0.42575],\n",
       "       [0.76755],\n",
       "       [0.7045 ],\n",
       "       [0.6629 ],\n",
       "       [0.5915 ],\n",
       "       [0.61285],\n",
       "       [0.40265],\n",
       "       [0.7045 ],\n",
       "       [0.76755],\n",
       "       [0.9337 ],\n",
       "       [0.9006 ],\n",
       "       [0.65825],\n",
       "       [0.5541 ],\n",
       "       [0.6629 ],\n",
       "       [0.59825],\n",
       "       [0.50235],\n",
       "       [0.64815],\n",
       "       [0.5578 ],\n",
       "       [0.9412 ],\n",
       "       [0.43395],\n",
       "       [0.93435],\n",
       "       [0.6563 ],\n",
       "       [0.9918 ],\n",
       "       [0.9251 ],\n",
       "       [0.93355],\n",
       "       [0.4358 ],\n",
       "       [0.9956 ],\n",
       "       [0.4277 ],\n",
       "       [0.83225],\n",
       "       [0.9412 ],\n",
       "       [0.83895],\n",
       "       [0.4913 ],\n",
       "       [0.5631 ],\n",
       "       [0.61285],\n",
       "       [0.98385],\n",
       "       [0.68075],\n",
       "       [0.99155],\n",
       "       [0.70285],\n",
       "       [0.7235 ],\n",
       "       [0.4944 ],\n",
       "       [0.6629 ],\n",
       "       [0.77415],\n",
       "       [0.9412 ],\n",
       "       [0.73865],\n",
       "       [0.49555],\n",
       "       [0.95775],\n",
       "       [0.8697 ],\n",
       "       [0.7704 ],\n",
       "       [0.74375],\n",
       "       [0.71   ],\n",
       "       [0.6629 ],\n",
       "       [0.9337 ],\n",
       "       [0.5178 ],\n",
       "       [0.76755],\n",
       "       [0.98425],\n",
       "       [0.9337 ],\n",
       "       [0.9709 ],\n",
       "       [0.67935],\n",
       "       [0.6152 ],\n",
       "       [0.9337 ],\n",
       "       [0.8719 ],\n",
       "       [0.99595],\n",
       "       [0.83615],\n",
       "       [0.9412 ],\n",
       "       [0.64545],\n",
       "       [0.67935],\n",
       "       [0.6152 ],\n",
       "       [0.6629 ],\n",
       "       [0.03945],\n",
       "       [0.70515],\n",
       "       [0.9412 ],\n",
       "       [0.90535],\n",
       "       [0.446  ],\n",
       "       [0.4393 ],\n",
       "       [0.9709 ],\n",
       "       [0.0464 ],\n",
       "       [0.42575],\n",
       "       [0.66375],\n",
       "       [0.6807 ],\n",
       "       [0.64545],\n",
       "       [0.61285],\n",
       "       [0.9337 ],\n",
       "       [0.8622 ],\n",
       "       [0.76755],\n",
       "       [0.9344 ],\n",
       "       [0.43625],\n",
       "       [0.93425],\n",
       "       [0.98415],\n",
       "       [0.6563 ],\n",
       "       [0.87555],\n",
       "       [0.99595],\n",
       "       [0.98855],\n",
       "       [0.8214 ],\n",
       "       [0.4468 ],\n",
       "       [0.77345],\n",
       "       [0.5541 ],\n",
       "       [0.99595],\n",
       "       [0.6954 ],\n",
       "       [0.42885],\n",
       "       [0.7611 ],\n",
       "       [0.9337 ],\n",
       "       [0.5578 ],\n",
       "       [0.84385],\n",
       "       [0.9709 ],\n",
       "       [0.04665],\n",
       "       [0.8651 ],\n",
       "       [0.4727 ],\n",
       "       [0.762  ],\n",
       "       [0.65825],\n",
       "       [0.99595],\n",
       "       [0.64145],\n",
       "       [0.40265],\n",
       "       [0.8214 ],\n",
       "       [0.9251 ],\n",
       "       [0.6807 ],\n",
       "       [0.42575],\n",
       "       [0.42055],\n",
       "       [0.40265],\n",
       "       [0.4468 ],\n",
       "       [0.42575],\n",
       "       [0.65825],\n",
       "       [0.99595],\n",
       "       [0.5644 ],\n",
       "       [0.64145],\n",
       "       [0.40265],\n",
       "       [0.92255],\n",
       "       [0.87415],\n",
       "       [0.99625],\n",
       "       [0.42575],\n",
       "       [0.47295],\n",
       "       [0.7704 ],\n",
       "       [0.6807 ],\n",
       "       [0.67935],\n",
       "       [0.99285],\n",
       "       [0.42575],\n",
       "       [0.64195],\n",
       "       [0.97955],\n",
       "       [0.7631 ],\n",
       "       [0.9883 ],\n",
       "       [0.9337 ],\n",
       "       [0.9709 ],\n",
       "       [0.04685],\n",
       "       [0.8651 ],\n",
       "       [0.9337 ],\n",
       "       [0.5578 ],\n",
       "       [0.86195],\n",
       "       [0.8724 ],\n",
       "       [0.71035],\n",
       "       [0.64545],\n",
       "       [0.43265],\n",
       "       [0.95265],\n",
       "       [0.93355],\n",
       "       [0.67935],\n",
       "       [0.58385],\n",
       "       [0.64195],\n",
       "       [0.84385],\n",
       "       [0.9838 ],\n",
       "       [0.56345],\n",
       "       [0.9365 ],\n",
       "       [0.4192 ],\n",
       "       [0.7237 ],\n",
       "       [0.6629 ],\n",
       "       [0.9709 ],\n",
       "       [0.0464 ],\n",
       "       [0.7995 ],\n",
       "       [0.7763 ],\n",
       "       [0.9412 ],\n",
       "       [0.9337 ],\n",
       "       [0.5578 ],\n",
       "       [0.93355],\n",
       "       [0.98415],\n",
       "       [0.64195],\n",
       "       [0.87555],\n",
       "       [0.93425],\n",
       "       [0.7763 ],\n",
       "       [0.8089 ],\n",
       "       [0.93555],\n",
       "       [0.5541 ],\n",
       "       [0.7607 ],\n",
       "       [0.74835],\n",
       "       [0.9412 ],\n",
       "       [0.9251 ],\n",
       "       [0.42885],\n",
       "       [0.9883 ],\n",
       "       [0.93425],\n",
       "       [0.93395],\n",
       "       [0.6124 ],\n",
       "       [0.42575],\n",
       "       [0.9475 ],\n",
       "       [0.98315],\n",
       "       [0.7687 ],\n",
       "       [0.81785],\n",
       "       [0.93815],\n",
       "       [0.9337 ],\n",
       "       [0.76755],\n",
       "       [0.77595],\n",
       "       [0.65825],\n",
       "       [0.9709 ],\n",
       "       [0.04665],\n",
       "       [0.9412 ],\n",
       "       [0.9337 ],\n",
       "       [0.48675],\n",
       "       [0.6629 ],\n",
       "       [0.44145],\n",
       "       [0.93355],\n",
       "       [0.67935],\n",
       "       [0.9412 ],\n",
       "       [0.5018 ],\n",
       "       [0.6629 ],\n",
       "       [0.9337 ],\n",
       "       [0.7478 ],\n",
       "       [0.62075],\n",
       "       [0.84175],\n",
       "       [0.97955],\n",
       "       [0.86505],\n",
       "       [0.93535],\n",
       "       [0.93605],\n",
       "       [0.88255],\n",
       "       [0.45275],\n",
       "       [0.64195],\n",
       "       [0.97955],\n",
       "       [0.9412 ],\n",
       "       [0.45105],\n",
       "       [0.43485],\n",
       "       [0.6629 ],\n",
       "       [0.9709 ],\n",
       "       [0.04665],\n",
       "       [0.64195],\n",
       "       [0.9304 ],\n",
       "       [0.9337 ],\n",
       "       [0.5578 ],\n",
       "       [0.93355],\n",
       "       [0.93555],\n",
       "       [0.98605],\n",
       "       [0.64145],\n",
       "       [0.9412 ],\n",
       "       [0.9251 ],\n",
       "       [0.93395],\n",
       "       [0.77845],\n",
       "       [0.80275],\n",
       "       [0.42575],\n",
       "       [0.81835],\n",
       "       [0.9883 ],\n",
       "       [0.93425],\n",
       "       [0.93555],\n",
       "       [0.98605],\n",
       "       [0.64145],\n",
       "       [0.9412 ],\n",
       "       [0.4795 ],\n",
       "       [0.93395],\n",
       "       [0.77845],\n",
       "       [0.8214 ],\n",
       "       [0.452  ],\n",
       "       [0.935  ],\n",
       "       [0.98605],\n",
       "       [0.45105],\n",
       "       [0.7585 ],\n",
       "       [0.70985],\n",
       "       [0.4286 ],\n",
       "       [0.6178 ],\n",
       "       [0.4288 ],\n",
       "       [0.42575],\n",
       "       [0.935  ],\n",
       "       [0.98605],\n",
       "       [0.45105],\n",
       "       [0.94   ],\n",
       "       [0.76755],\n",
       "       [0.98415],\n",
       "       [0.93555],\n",
       "       [0.98605],\n",
       "       [0.64145],\n",
       "       [0.9412 ],\n",
       "       [0.9251 ],\n",
       "       [0.47855],\n",
       "       [0.76755],\n",
       "       [0.93435],\n",
       "       [0.9365 ],\n",
       "       [0.97955],\n",
       "       [0.6616 ],\n",
       "       [0.47335],\n",
       "       [0.9337 ],\n",
       "       [0.83625],\n",
       "       [0.9412 ],\n",
       "       [0.9337 ],\n",
       "       [0.92255],\n",
       "       [0.69315],\n",
       "       [0.93355],\n",
       "       [0.64195],\n",
       "       [0.97955],\n",
       "       [0.62895],\n",
       "       [0.9412 ],\n",
       "       [0.45105],\n",
       "       [0.43485],\n",
       "       [0.42575],\n",
       "       [0.6951 ],\n",
       "       [0.4358 ],\n",
       "       [0.40265],\n",
       "       [0.52855],\n",
       "       [0.9337 ],\n",
       "       [0.48785],\n",
       "       [0.46895],\n",
       "       [0.41515],\n",
       "       [0.6476 ],\n",
       "       [0.98315],\n",
       "       [0.7053 ],\n",
       "       [0.9412 ],\n",
       "       [0.45105],\n",
       "       [0.7845 ],\n",
       "       [0.77015],\n",
       "       [0.9412 ],\n",
       "       [0.64815],\n",
       "       [0.5578 ],\n",
       "       [0.6629 ],\n",
       "       [0.9709 ],\n",
       "       [0.04685],\n",
       "       [0.98145],\n",
       "       [0.8724 ],\n",
       "       [0.93355],\n",
       "       [0.9337 ],\n",
       "       [0.5578 ],\n",
       "       [0.64145],\n",
       "       [0.92515],\n",
       "       [0.94265],\n",
       "       [0.70725],\n",
       "       [0.6807 ],\n",
       "       [0.67935],\n",
       "       [0.7607 ],\n",
       "       [0.9337 ],\n",
       "       [0.60785],\n",
       "       [0.9399 ],\n",
       "       [0.93355],\n",
       "       [0.9337 ],\n",
       "       [0.5578 ],\n",
       "       [0.62975],\n",
       "       [0.64815],\n",
       "       [0.7276 ],\n",
       "       [0.99295],\n",
       "       [0.93555],\n",
       "       [0.6371 ],\n",
       "       [0.5647 ],\n",
       "       [0.9365 ],\n",
       "       [0.77015],\n",
       "       [0.8781 ],\n",
       "       [0.67195],\n",
       "       [0.76755],\n",
       "       [0.95785],\n",
       "       [0.9337 ],\n",
       "       [0.76755],\n",
       "       [0.64815],\n",
       "       [0.99015],\n",
       "       [0.93555],\n",
       "       [0.8075 ],\n",
       "       [0.6476 ],\n",
       "       [0.9883 ],\n",
       "       [0.95265],\n",
       "       [0.97955],\n",
       "       [0.78875],\n",
       "       [0.92515],\n",
       "       [0.47335],\n",
       "       [0.9365 ],\n",
       "       [0.81495],\n",
       "       [0.5111 ],\n",
       "       [0.9337 ],\n",
       "       [0.5591 ],\n",
       "       [0.47335],\n",
       "       [0.86505],\n",
       "       [0.93355],\n",
       "       [0.67935],\n",
       "       [0.58385],\n",
       "       [0.9337 ],\n",
       "       [0.5578 ],\n",
       "       [0.52415],\n",
       "       [0.7607 ],\n",
       "       [0.95775],\n",
       "       [0.98535],\n",
       "       [0.6371 ],\n",
       "       [0.9412 ],\n",
       "       [0.5542 ],\n",
       "       [0.68975],\n",
       "       [0.93035],\n",
       "       [0.93425],\n",
       "       [0.7775 ],\n",
       "       [0.42575],\n",
       "       [0.7775 ],\n",
       "       [0.4151 ],\n",
       "       [0.93355],\n",
       "       [0.64195],\n",
       "       [0.9918 ],\n",
       "       [0.89605],\n",
       "       [0.7607 ],\n",
       "       [0.45105],\n",
       "       [0.9883 ],\n",
       "       [0.93425],\n",
       "       [0.4727 ],\n",
       "       [0.93555],\n",
       "       [0.52415],\n",
       "       [0.7607 ],\n",
       "       [0.63195],\n",
       "       [0.9365 ],\n",
       "       [0.93555],\n",
       "       [0.97835],\n",
       "       [0.93395],\n",
       "       [0.7278 ],\n",
       "       [0.9412 ],\n",
       "       [0.45105],\n",
       "       [0.40265],\n",
       "       [0.80005],\n",
       "       [0.6997 ],\n",
       "       [0.98495],\n",
       "       [0.9918 ],\n",
       "       [0.69965],\n",
       "       [0.93425],\n",
       "       [0.6629 ],\n",
       "       [0.41515],\n",
       "       [0.9337 ],\n",
       "       [0.93355],\n",
       "       [0.67935],\n",
       "       [0.98535],\n",
       "       [0.93555],\n",
       "       [0.98315],\n",
       "       [0.8923 ],\n",
       "       [0.6892 ],\n",
       "       [0.77015],\n",
       "       [0.80755],\n",
       "       [0.6476 ],\n",
       "       [0.9883 ],\n",
       "       [0.9337 ],\n",
       "       [0.93555],\n",
       "       [0.6371 ],\n",
       "       [0.7585 ],\n",
       "       [0.6573 ],\n",
       "       [0.93355],\n",
       "       [0.97955],\n",
       "       [0.8365 ],\n",
       "       [0.9412 ],\n",
       "       [0.40265],\n",
       "       [0.5548 ],\n",
       "       [0.69215],\n",
       "       [0.76755],\n",
       "       [0.9845 ],\n",
       "       [0.93555],\n",
       "       [0.98315],\n",
       "       [0.9412 ],\n",
       "       [0.45105],\n",
       "       [0.40265],\n",
       "       [0.7832 ],\n",
       "       [0.76755],\n",
       "       [0.9337 ],\n",
       "       [0.5578 ],\n",
       "       [0.52415],\n",
       "       [0.77085],\n",
       "       [0.78805],\n",
       "       [0.76755],\n",
       "       [0.40265],\n",
       "       [0.69215],\n",
       "       [0.77015],\n",
       "       [0.57225],\n",
       "       [0.82905],\n",
       "       [0.9333 ],\n",
       "       [0.9337 ],\n",
       "       [0.7704 ],\n",
       "       [0.6629 ],\n",
       "       [0.6436 ],\n",
       "       [0.95775],\n",
       "       [0.93355],\n",
       "       [0.751  ],\n",
       "       [0.6738 ],\n",
       "       [0.64815],\n",
       "       [0.6119 ],\n",
       "       [0.9412 ],\n",
       "       [0.9251 ],\n",
       "       [0.9618 ],\n",
       "       [0.4343 ],\n",
       "       [0.6629 ],\n",
       "       [0.9365 ],\n",
       "       [0.97955],\n",
       "       [0.49555],\n",
       "       [0.6629 ],\n",
       "       [0.59   ],\n",
       "       [0.6629 ],\n",
       "       [0.03945],\n",
       "       [0.0533 ],\n",
       "       [0.98415],\n",
       "       [0.64815],\n",
       "       [0.5578 ],\n",
       "       [0.61285],\n",
       "       [0.96455],\n",
       "       [0.9337 ],\n",
       "       [0.92255],\n",
       "       [0.41515],\n",
       "       [0.9337 ],\n",
       "       [0.8767 ],\n",
       "       [0.76755],\n",
       "       [0.9337 ],\n",
       "       [0.64695],\n",
       "       [0.80925],\n",
       "       [0.98415],\n",
       "       [0.93555],\n",
       "       [0.47605],\n",
       "       [0.9412 ],\n",
       "       [0.4348 ],\n",
       "       [0.6476 ],\n",
       "       [0.4358 ],\n",
       "       [0.6206 ],\n",
       "       [0.59   ],\n",
       "       [0.6289 ],\n",
       "       [0.8923 ],\n",
       "       [0.6008 ],\n",
       "       [0.4358 ],\n",
       "       [0.9412 ],\n",
       "       [0.6427 ],\n",
       "       [0.9337 ],\n",
       "       [0.71665],\n",
       "       [0.6697 ],\n",
       "       [0.47335],\n",
       "       [0.9337 ],\n",
       "       [0.5578 ],\n",
       "       [0.5541 ],\n",
       "       [0.7607 ],\n",
       "       [0.5118 ],\n",
       "       [0.9734 ],\n",
       "       [0.4358 ],\n",
       "       [0.40265],\n",
       "       [0.72395],\n",
       "       [0.61285],\n",
       "       [0.64815],\n",
       "       [0.8213 ],\n",
       "       [0.5189 ],\n",
       "       [0.9365 ],\n",
       "       [0.45345],\n",
       "       [0.9883 ],\n",
       "       [0.93355],\n",
       "       [0.76755],\n",
       "       [0.5394 ],\n",
       "       [0.42575],\n",
       "       [0.99595],\n",
       "       [0.98605],\n",
       "       [0.49555],\n",
       "       [0.8724 ],\n",
       "       [0.93355],\n",
       "       [0.97955],\n",
       "       [0.7607 ],\n",
       "       [0.4358 ],\n",
       "       [0.64195],\n",
       "       [0.4942 ],\n",
       "       [0.9204 ],\n",
       "       [0.64765],\n",
       "       [0.9412 ],\n",
       "       [0.9337 ],\n",
       "       [0.42575],\n",
       "       [0.42   ],\n",
       "       [0.64765],\n",
       "       [0.9412 ],\n",
       "       [0.45105],\n",
       "       [0.52975],\n",
       "       [0.64195],\n",
       "       [0.55415],\n",
       "       [0.6283 ],\n",
       "       [0.7763 ],\n",
       "       [0.6629 ],\n",
       "       [0.40265],\n",
       "       [0.4602 ],\n",
       "       [0.76755],\n",
       "       [0.6277 ],\n",
       "       [0.4727 ],\n",
       "       [0.82905],\n",
       "       [0.97955],\n",
       "       [0.59235],\n",
       "       [0.70515],\n",
       "       [0.40265],\n",
       "       [0.5036 ],\n",
       "       [0.52855],\n",
       "       [0.6563 ],\n",
       "       [0.6508 ],\n",
       "       [0.9365 ],\n",
       "       [0.71615],\n",
       "       [0.6807 ],\n",
       "       [0.40265],\n",
       "       [0.7074 ],\n",
       "       [0.73865],\n",
       "       [0.4953 ],\n",
       "       [0.6287 ],\n",
       "       [0.45105],\n",
       "       [0.9883 ],\n",
       "       [0.99595],\n",
       "       [0.70105],\n",
       "       [0.98285],\n",
       "       [0.98415],\n",
       "       [0.9337 ],\n",
       "       [0.75675],\n",
       "       [0.60295],\n",
       "       [0.7684 ],\n",
       "       [0.5018 ],\n",
       "       [0.9412 ],\n",
       "       [0.74425],\n",
       "       [0.65275],\n",
       "       [0.9412 ],\n",
       "       [0.48905],\n",
       "       [0.7763 ],\n",
       "       [0.74425],\n",
       "       [0.5967 ],\n",
       "       [0.98195],\n",
       "       [0.4743 ],\n",
       "       [0.68795],\n",
       "       [0.45105],\n",
       "       [0.9196 ],\n",
       "       [0.7607 ],\n",
       "       [0.9412 ],\n",
       "       [0.8821 ],\n",
       "       [0.4393 ],\n",
       "       [0.93425],\n",
       "       [0.9282 ],\n",
       "       [0.6956 ],\n",
       "       [0.42575],\n",
       "       [0.6252 ],\n",
       "       [0.4098 ],\n",
       "       [0.9336 ],\n",
       "       [0.80835],\n",
       "       [0.7423 ],\n",
       "       [0.9337 ],\n",
       "       [0.4668 ],\n",
       "       [0.98415],\n",
       "       [0.9337 ],\n",
       "       [0.7086 ],\n",
       "       [0.69335],\n",
       "       [0.77015],\n",
       "       [0.93395],\n",
       "       [0.56485],\n",
       "       [0.76755],\n",
       "       [0.5252 ],\n",
       "       [0.98415],\n",
       "       [0.434  ],\n",
       "       [0.72645],\n",
       "       [0.93425],\n",
       "       [0.98855],\n",
       "       [0.6807 ],\n",
       "       [0.97955],\n",
       "       [0.40265],\n",
       "       [0.5548 ],\n",
       "       [0.7217 ],\n",
       "       [0.98535],\n",
       "       [0.5541 ],\n",
       "       [0.93555],\n",
       "       [0.7607 ],\n",
       "       [0.69345],\n",
       "       [0.93355],\n",
       "       [0.93535],\n",
       "       [0.72645],\n",
       "       [0.98315],\n",
       "       [0.60295],\n",
       "       [0.7684 ],\n",
       "       [0.98535],\n",
       "       [0.97955],\n",
       "       [0.935  ],\n",
       "       [0.40265],\n",
       "       [0.74835],\n",
       "       [0.61285],\n",
       "       [0.40265],\n",
       "       [0.61205],\n",
       "       [0.9742 ],\n",
       "       [0.4393 ],\n",
       "       [0.4192 ],\n",
       "       [0.55415],\n",
       "       [0.64145],\n",
       "       [0.40265],\n",
       "       [0.60455],\n",
       "       [0.99015],\n",
       "       [0.4045 ],\n",
       "       [0.91415],\n",
       "       [0.9412 ],\n",
       "       [0.6303 ],\n",
       "       [0.44275],\n",
       "       [0.7907 ],\n",
       "       [0.7133 ],\n",
       "       [0.9774 ],\n",
       "       [0.9337 ],\n",
       "       [0.8887 ],\n",
       "       [0.67935],\n",
       "       [0.70485],\n",
       "       [0.40565],\n",
       "       [0.51   ],\n",
       "       [0.48475],\n",
       "       [0.70285],\n",
       "       [0.9633 ],\n",
       "       [0.9412 ],\n",
       "       [0.9337 ],\n",
       "       [0.7499 ],\n",
       "       [0.4151 ],\n",
       "       [0.95955],\n",
       "       [0.76755],\n",
       "       [0.69015],\n",
       "       [0.7986 ],\n",
       "       [0.4148 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "source": [
    "data = data.reshape(-1, data.shape[1], 1)\n",
    "data = data/VOCAB_SIZE\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "source": [
    "onehot = pd.get_dummies(df['label'])\n",
    "target_labels = onehot.columns\n",
    "target = onehot.as_matrix()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 15,
   "metadata": {},
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "outputs": [],
   "source": [
    "x_train = data[:TRAIN_SIZE]\n",
    "x_test = data[TRAIN_SIZE:]\n",
    "\n",
    "y_train = target[:TRAIN_SIZE]\n",
    "y_test = target[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 16,
   "metadata": {},
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=data.shape[1:]))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(35))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(target.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 17,
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000, 128)         256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000, 128)         16512     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 996, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 199, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 195, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 35, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 281,617\n",
      "Trainable params: 281,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 4393 samples\n",
      "Epoch 1/2\n",
      "11264/15000 [=====================>........] - ETA: 81s - loss: 2.7783 - acc: 0.1401"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-368cdf934484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-891cdcbaae37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membedded_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# Infering the output shape is only relevant for Theano.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 new_dim = conv_utils.conv_output_length(\n\u001b[1;32m    190\u001b[0m                     \u001b[0mspace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                     \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "source": [
    "embedding_layer = Embedding(len(embed_matrix), len(embed_matrix.columns), weights=[random_matrix],\n",
    "                            input_length=data.shape[1:], trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAXLEN,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(target.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "collapsed": true
   },
=======
   "metadata": {},
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "collapsed": true
   },
=======
   "metadata": {},
>>>>>>> e7134105f41afe68ee253d9881e0383c164eed59
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=data.shape[1:], return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(target.shape[1], activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-3, decay=1e-5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
